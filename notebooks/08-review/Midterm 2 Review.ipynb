{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1e920b1",
   "metadata": {},
   "source": [
    "# Topics\n",
    "\n",
    "1. Pytorch basics: https://colab.research.google.com/github/wecacuee/ECE490-Neural-Networks/blob/master//notebooks/06-pytorch/NumpyTutorial-Pytorched.ipynb\n",
    "    (you should understand basic mathematical operations and broadcasting).\n",
    "\n",
    "2. Autograd Mathematics (only math no code): https://colab.research.google.com/github/wecacuee/ECE490-Neural-Networks/blob/master/notebooks/03-autograd/AutogradNumpy.ipynb\n",
    "\n",
    "3. Probability problems ( below) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf588a5",
   "metadata": {},
   "source": [
    "## Probability definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceecd18e",
   "metadata": {},
   "source": [
    "#### Q1: Define Sample Space\n",
    "\n",
    "Sample space is the set all possible of outcomes of an experiment, denoted by $\\Omega$.\n",
    "\n",
    "For example,\n",
    "For 2-coin tosses the sample space is \n",
    "$$ \\Omega_{\\text{2-coin}} = \\{ HH, HT, TH, TT \\}$$\n",
    "\n",
    "For roll of a dice with 6-sides\n",
    "\n",
    "$$ \\Omega_{\\text{dice}} = \\{1, 2, 3, 4, 5, 6 \\}$$\n",
    "\n",
    "For weight measurements of an individual, the sample space is the set of all positive real numbers\n",
    "\n",
    "$\\newcommand{\\bbR}{\\mathbb{R}}$\n",
    "$$ \\Omega_{\\text{weight}} = \\bbR^+$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671cf3f8",
   "metadata": {},
   "source": [
    "#### Q2: Define Event Space\n",
    "\n",
    "An event is the set of outcomes that we might be interested in.\n",
    "\n",
    "Event space is a set of subsets of the sample space.\n",
    "\n",
    "or example,\n",
    "For 2-coin tosses the set of all subsets of the sample space in cluding the null set $\\{\\}$ and the full sample $\\Omega$ \n",
    "$$ \\mathcal{F}_{\\text{2-coin}} = \\{ \\{\\}, \\{ HH \\}  \\{ HT \\}, \\{ TH \\}, \\{ TT \\}, \\{ HH, HT \\}, \\dots, \\underbrace{\\{ HH, HT, TH, TT \\}}_\\Omega \\}$$\n",
    "\n",
    "\n",
    "For weight measurements of an individual, the event space is be the set of all unions and intersections of intervals (open and closed) of sample space (positive real numbers). \n",
    "\n",
    "$\\newcommand{\\bbR}{\\mathbb{R}}$\n",
    "$$ \\mathcal{F}_{\\text{weight}} = \\{ \\cup_{i} \\cap_j  [a_{ij}, b_{ij}] : a_{ij} < b_{ij}, a_{ij} \\in \\bbR ,  b_{ij} \\in \\bbR\\} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ada3c4",
   "metadata": {},
   "source": [
    "#### Q3: Define Power set\n",
    "\n",
    "The set of all possible subsets of a set $\\Omega$ is called a power set and is denoted by $2^{\\Omega}$.\n",
    "\n",
    "For roll of a dice with 6-sides\n",
    "\n",
    "$$ 2^{\\Omega} = \\{ \\{\\}, \\{ HH \\}  \\{ HT \\}, \\{ TH \\}, \\{ TT \\}, \\{ HH, HT \\}, \\dots, \\underbrace{\\{ HH, HT, TH, TT \\}}_\\Omega \\}$$\n",
    "\n",
    "For discrete sample space, event space is the power set of the sample space. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064f01e8-01c5-42fa-8cd4-e63bcc5398d7",
   "metadata": {},
   "source": [
    "#### Q4: Define Probability measure\n",
    "\n",
    "Probability measure is a function $P: \\mathcal{F} \\to [0, 1]$ that maps from event space to real numbers between $[0, 1]$ and satisfy the following Kolmogorov axioms\n",
    "\n",
    "1. $P(E) \\in [0, 1]$ for all  $E \\in \\mathcal{F}$, where $\\mathcal{F}$ is event space\n",
    "2. $P(\\Omega) = 1 $, where $\\Omega$ is sample space\n",
    "3. For all disjoint set of events $A_1$, $A_2$ ($A_1 \\cap A_2 = \\phi$), the probability of union of events is the sum of individual event probabilities:\n",
    "   $$ P(A_1) + P(A_2) = P(A_1 \\cup A_2)$$  when $A_1 \\cap A_2 = \\phi$.\n",
    "   \n",
    "   In general, for a countably infinite set of event $A_1, A_2, \\dots A_n \\dots \\infty$,\n",
    "   $$ P\\left(\\bigcup_{n=1}^\\infty A_n\\right) = \\sum_{n=1}^\\infty P(A_n)$$ when $A_i \\cap A_j = \\infty$ for all $ i \\ne j$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74a0051-d7ff-485a-a96b-8fef837945b5",
   "metadata": {},
   "source": [
    "#### Q5: Define Probability space\n",
    "\n",
    "The triple of sample space $\\Omega$, event space $\\mathcal{F}$ and a probability measure $P: \\mathcal{F} \\to [0, 1]$ is called a probability space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291f99ec-1f24-4ac9-a320-d1e3302d5fc0",
   "metadata": {},
   "source": [
    "#### Q6: Define Random variable\n",
    "\n",
    "A random variable is a function $X: \\Omega \\to \\mathbb{Q}$ that maps from sample space $\\Omega$ to a space of integers $\\mathbb{Z}$ or real numbers $\\mathbb{R}$ (in general a measurable space), such that a preimage $X^{-1}(B) \\in \\Omega$ of any set of numbers $B \\in \\mathbb{Q}$ exists in the sample space.\n",
    "\n",
    "For example, a 2-coin toss:\n",
    "$$ \\Omega = \\{ HH, HT, TH, TT \\}$$\n",
    "A random variable maps the elements of sample space to a number,\n",
    "$$ X(HH) = 0, X(HT) = 1, X(TH) = 2, X(TT) = 3 $$\n",
    "\n",
    "By slight abuse of notation, the random variable also maps events to a set of numbers $X: \\mathcal{F} \\to B $,\n",
    "$$ X(\\{HT, TH, TT\\}) = \\{1, 2, 3\\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ece64e7-9d9c-4563-9741-ea271c813541",
   "metadata": {},
   "source": [
    "#### Q7: What is the difference between discrete and continuous random variable\n",
    "\n",
    "Discrete random variable: When the random variable maps the sample space to integers, then the random variable is discrete.\n",
    "\n",
    "Continuous random variable: When the random variable maps the sample space to real numbers then the random variable is continuous."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e35c7d-21d3-4e7f-bf63-cd443b2492c7",
   "metadata": {},
   "source": [
    "#### Q8: Define Probability mass function (PMF)\n",
    "\n",
    "For a discrete random variable (RV) the Probability mass function (PMF) is a function that assigns probability value to every discrete value of the random variable, such that $$\\sum_{x \\in \\Omega} P(X = x) = 1.$$\n",
    "\n",
    "For example, a die roll\n",
    "$$\\Omega = \\{1, \\dots, 6\\}$$\n",
    "$$ P(X=1) = 1/6, P(X=2) = 1/6, \\dots, P(X=6)  = 1/6 $$\n",
    "\n",
    "![](imgs/Fair_dice_probability_distribution.svg)\n",
    "\n",
    "PMF is denoted as multiple symbols $P(X=x) = P_X(x) = P(x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8f00fb-3e54-48f3-8335-7a5c9338254d",
   "metadata": {},
   "source": [
    "#### Q9: Define probability density function (PDF)\n",
    "\n",
    "For a continuous random variable $X: \\Omega \\to \\mathbb{R}$, the probability density function (PDF) is a function $f_X : \\mathbb{R} \\to [0, \\infty)$ such that:\n",
    "1. $f_X(x) \\ge 0$ for all $x \\in \\mathbb{R}$\n",
    "2. $\\int_{\\mathbb{R}} f_X(x) dx = 1$\n",
    "3. $P(a \\le X \\le b) = P(X \\in [a, b]) = \\int_a^b f_X(x) dx$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc11b66-c97a-4494-9b08-aadfdedbbc4f",
   "metadata": {},
   "source": [
    "#### Q10: Define joint probability mass function\n",
    "\n",
    "$$ P(X=x, Y=y) = P((X=x) \\cap (Y=y)) = P((X=x) \\text{ AND } (Y=y))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ee628b-bdc5-47ba-8f22-13604d1e16c2",
   "metadata": {},
   "source": [
    "#### Q11: Define joint probability density function\n",
    "\n",
    "For two continuous random variable $X$ and $Y$, the joint probability density function (PDF) is a function $f_{X,Y} : (\\mathbb{R}, \\mathbb{R}) \\to [0, \\infty)$ such that:\n",
    "1. $f_{X,Y}(x, y) \\ge 0$ for all $x, y \\in \\mathbb{R}$\n",
    "2. $\\int_{\\mathbb{R}} \\int_{\\mathbb{R}} f_{X, Y}(x, y) dx dy = 1$\n",
    "3. $P(a \\le X \\le b, c \\le Y \\le d) = P(X \\in [a, b], Y \\in [c, d]) = \\int_c^d\\int_a^b f_{X,Y}(x, y) dx dy$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4b4f1d-458d-4429-a93a-b2e1958c6922",
   "metadata": {},
   "source": [
    "#### Q12: Define cumulative distribution function\n",
    "\n",
    "A cumulative distribution function (CDF) is $F_X(x)$ is defined as\n",
    "$$F_X(x) = P(X \\le x).$$\n",
    "\n",
    "For a discrete random variable, CDF is the sum of probability mass function $$F_X(x) = P(X \\le x) = \\sum_{a \\le x} P_X(a)$$\n",
    "\n",
    "\n",
    "For a continuous random variable, CDF is the integral of probability density function $$F_X(x) = P(X \\le x) = \\int_{-\\infty}^{x} f_X(z) dz$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9d1044-7a42-48b3-ac35-a944f4352908",
   "metadata": {},
   "source": [
    "#### Q13: Define conditional probability \n",
    "\n",
    "Conditional probability of event $A$ given event $B$ is defined as\n",
    "$$ P(A | B) = \\frac{P(A, B)}{P(B)}$$ when $P(B) \\ne 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcf736b-78e9-42f8-a2e6-2f34ebc37c6a",
   "metadata": {},
   "source": [
    "#### Q14: State Bayes theorem\n",
    "\n",
    "For any two events, $A$ and $B$ $$P(A|B) = \\frac{P(B|A) P(A)}{P(B)}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98af98e-7621-44e5-b7c0-ffec52485cc2",
   "metadata": {},
   "source": [
    "#### Q15: State Bayes theorem in terms of likelihood, prior, evidence and posterior\n",
    "\n",
    "For an observable event $D$ and a hidden event $\\theta$, the posterior $P(\\theta|D)$ can be estimated using Bayes theorem in terms of likelihood $P(D|\\theta)$, prior $P(\\theta)$ and evidence $P(D)$ as\n",
    "\n",
    "$$P(\\theta|D) = \\frac{P(D|\\theta) P(\\theta)}{P(D)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4dd4ac-0374-4690-a5e0-e0bd9ca939cb",
   "metadata": {},
   "source": [
    "#### Q16: Define statistical independence\n",
    "\n",
    "Two random variables $X$ and $Y$ are said to be independent, denoted as $X \\perp Y$ if any of the following equivalent condition hold for all $x, y$ :\n",
    "1. $$P(X = x, Y = y) = P(X = x) P(Y = y)$$ \n",
    "2. $$P(X = x| Y = y) = P(X = x) $$ \n",
    "3. $$P(Y = y| X = x) = P(Y = y) $$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ee96f0-0af8-4d56-a912-462804ddc75f",
   "metadata": {},
   "source": [
    "#### Q17: Define conditional independence\n",
    "\n",
    "Two random variables $X$ and $Y$ are said to be conditionally independent given random variable $Z$, denoted as $X \\perp Y | Z$ if  for all $x, y, z$ :\n",
    " $$P(X = x, Y = y | Z = z) = P(X = x | Z = z) P(Y = y | Z = z)$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c43b31-021e-4146-971d-ad6c5784287f",
   "metadata": {},
   "source": [
    "#### Q18: Identically independently distributed (IID)\n",
    "\n",
    "The random variables (RVs) $X_1, X_2, \\dots, X_n$ are identically independently distributed if they are mutually independent $X_i \\perp X_j$ and have the same probability distributions $P_{X_i}(x_i) = P_{X_j}(x_j)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb72ff7-33b8-4988-a206-34894ddde9fa",
   "metadata": {},
   "source": [
    "#### Q19: Expectation of a function of a random variable\n",
    "\n",
    "The expectation of a function $g(X)$ of a discrete random variable $X$ is defined as:\n",
    "$$ \\mathbb{E}_X[g(X)] = \\sum_{x \\in \\mathbb{Z}} P(X=x) g(x)$$\n",
    "\n",
    "The expectation of a function $g(X)$ of a continuous random variable $X$ is defined as:\n",
    "$$ \\mathbb{E}_X[g(X)] = \\int_{x \\in \\mathbb{R}} f_X(x) g(x) dx$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d970adba-6717-4089-af75-21d05b07082d",
   "metadata": {},
   "source": [
    "#### Q20: What is the difference between sample mean and expectation\n",
    "\n",
    "Sample mean of n samples is \n",
    "$$ \\mu(X_1, \\dots, X_n) = \\frac{1}{n} \\sum_{i=1}^n X_i$$\n",
    "\n",
    "Expectation of a discrete random variable is\n",
    "$\\newcommand{\\bbE}{\\mathbb{E}}$\n",
    "$$ \\bbE_X[X] = \\sum_{x \\in \\Omega_X} P(X=x) x$$\n",
    "\n",
    "Sample mean converges to the expectation when $n$ with high probability:\n",
    "\n",
    "$$ \\lim_{n \\to \\infty} \\mu(X_1, \\dots, X_n) = E_X[X] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0ddfb5-6dc7-492b-b1f5-4cbf45e71ae3",
   "metadata": {},
   "source": [
    "#### Q21: Define variance of a function of a random variable\n",
    "The expectation of a function $g(X)$ of a random variable $X$ is given by\n",
    "\n",
    "$\\newcommand{\\bbV}{\\mathbb{V}}$\n",
    "$$ \\bbV_X[g(X)] = \\bbE_X\\left[ \\left(g(X) - \\bbE_X[g(X)]\\right)^2 \\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8eb48ef-ec8b-48a0-bd54-caf7aa8004b1",
   "metadata": {},
   "source": [
    "#### Q22: Define a covariance matrix\n",
    "\n",
    "$\\newcommand{\\bfX}{\\mathbf{X}}$\n",
    "For random vector $\\bfX = [X_1, X_2, \\dots, X_n]$, the covariance matrix of $X$ is defined as:\n",
    "\n",
    "$$ \\bbV_X[\\bfX] = \\bbE_X\\left[ \\left(\\bfX - \\bbE_X[\\bfX]\\right)  \\left(\\bfX - \\bbE_X[\\bfX]\\right)^\\top\\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea236704-0e6e-464c-87b9-7c8bb8c9677e",
   "metadata": {},
   "source": [
    "#### Q23: \n",
    "$\\newcommand{\\calD}{\\mathcal{D}}$\n",
    "$\\newcommand{\\bfx}{\\mathbf{x}}$\n",
    "Given the dataset $\\calD = \\{ (\\bfx_1, y_1), \\dots, (\\bfx_n, y_n) \\}$, a model $\\hat{y}_i = f(\\bfx_i; \\theta)$, and a loss function $l(y_i, \\hat{y}_i)$, show that the following optimization problem can be interpreted as maximum likelihood estimation. In the process show that for the interpretation, we need the IID (independently, identically distributed) assumption over the dataset. List any other assumptions that you need for the interpretation.\n",
    "\n",
    "$$ \\theta^* = \\arg~\\min_\\theta \\sum_{i=1}^n l(y_i, f(\\bfx_i; \\theta))$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69b5232-47fd-4dba-bd76-f3b454b60d80",
   "metadata": {},
   "source": [
    "#### A23:\n",
    "\n",
    "Let the $\\bfx_i$ and $y_i$ be random vectors for all $i$. Model the probability distribution as a negative log of the loss function:\n",
    "\n",
    "$$ P((\\bfx_i, y_i)| \\theta) = \\frac{1}{Z} \\exp(-l(y_i, f(\\bfx_i; \\theta)).$$\n",
    "\n",
    "If the samples are IID, then we can write the probability of the entire dataset as products of sample probabilities\n",
    "\n",
    "$$ P(\\calD|\\theta) = \\prod_{i=1}^n P((\\bfx_i, y_i)| \\theta) $$\n",
    "\n",
    "$$ P(\\calD|\\theta) = \\prod_{i=1}^n \\frac{1}{Z} \\exp(-l(y_i, f(\\bfx_i; \\theta)).$$\n",
    "\n",
    "A product of exponents is the summation of their powers,\n",
    "\n",
    "$$ P(\\calD|\\theta) = \\frac{1}{Z} \\exp(-\\sum_{i=1}^n l(y_i, f(\\bfx_i; \\theta)).$$\n",
    "\n",
    "Denote $$ L(\\calD; \\theta) = \\sum_{i=1}^n l(y_i, f(\\bfx_i; \\theta).$$\n",
    "\n",
    "The original optimization problem can be written as:\n",
    "$$ \\theta^* = \\arg~\\min_\\theta L(\\calD; \\theta)$$\n",
    "\n",
    "Taking negative exponent on both sides turns the problem into a maximization problem because $\\exp(-y)$ is a monotonically decreasing function.\n",
    "$$ \\theta^* = \\arg~\\max_\\theta \\exp(-L(\\calD; \\theta))$$\n",
    "\n",
    "This problem is the same as maximizing the likelihood $P(\\calD|\\theta)$, hence maximum likelihood estimate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c1bb79-85e1-45f6-905d-c74f3477a859",
   "metadata": {},
   "source": [
    "#### Q24:\n",
    "\n",
    "Given the dataset $\\calD = \\{ (\\bfx_1, y_1), \\dots, (\\bfx_n, y_n) \\}$, a model $\\hat{y}_i = f(\\bfx_i; \\theta)$, a regularizer $R(\\theta)$ and a loss function $l(y_i, \\hat{y}_i)$, show that the following optimization problem can be interpreted as maximum-a-posteriori estimation. In the process show that for the interpretation, we need the IID (independently, identically distributed) assumption over the dataset. List any other assumptions that you need for the interpretation.\n",
    "\n",
    "$$ \\theta^* = \\arg~\\min_\\theta \\sum_{i=1}^n l(y_i, f(\\bfx_i; \\theta)) + \\lambda R(\\theta),$$\n",
    "\n",
    "where $\\lambda$ is some positive constant that balances between the loss function and the regularizer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f21185-dcbb-406c-93e4-a6e9322a10f5",
   "metadata": {},
   "source": [
    "#### A24:\n",
    "\n",
    "Let the $\\bfx_i$ and $y_i$ be random vectors for all $i$. Model the probability distribution as a negative log of the loss function:\n",
    "\n",
    "$$ P((\\bfx_i, y_i)| \\theta) = \\frac{1}{Z} \\exp(-l(y_i, f(\\bfx_i; \\theta)).$$\n",
    "\n",
    "If the samples are IID, then we can write the probability of the entire dataset as products of sample probabilities\n",
    "\n",
    "$$ P(\\calD|\\theta) = \\prod_{i=1}^n P((\\bfx_i, y_i)| \\theta) $$\n",
    "\n",
    "$$ P(\\calD|\\theta) = \\prod_{i=1}^n \\frac{1}{Z} \\exp(-l(y_i, f(\\bfx_i; \\theta)).$$\n",
    "\n",
    "A product of exponents is the summation of their powers,\n",
    "\n",
    "$$ P(\\calD|\\theta) = \\frac{1}{Z} \\exp(-\\sum_{i=1}^n l(y_i, f(\\bfx_i; \\theta)).$$\n",
    "\n",
    "Denote $$ L(\\calD; \\theta) = \\sum_{i=1}^n l(y_i, f(\\bfx_i; \\theta).$$\n",
    "\n",
    "The original optimization problem can be written as:\n",
    "$$ \\theta^* = \\arg~\\min_\\theta L(\\calD; \\theta) + \\lambda R(\\theta)$$\n",
    "\n",
    "Taking negative exponent on both sides turns the problem into a maximization problem because $\\exp(-y)$ is a monotonically decreasing function.\n",
    "$$ \\theta^* = \\arg~\\max_\\theta \\exp(-L(\\calD; \\theta))\\exp(-\\lambda R(\\theta))$$\n",
    "\n",
    "The first term is the same as maximizing the likelihood $P(\\calD|\\theta)$. If we interpret the second term as a prior:\n",
    "$$ P(\\theta) = \\frac{1}{Z'} \\exp(-\\lambda R(\\theta)),$$\n",
    "\n",
    "then we can rewrite the original optimization problem as\n",
    "\n",
    "$$ \\theta^* = \\arg~\\max_\\theta P(\\calD|\\theta) P(\\theta) $$\n",
    "\n",
    "By Bayes theorem $P(\\calD|\\theta) P(\\theta) = P(\\theta|\\calD)P(\\calD)$, hence we can write the optimization problem as maximizing the posterior\n",
    "\n",
    "$$ \\theta^* = \\arg~\\max_\\theta P(\\theta|\\calD) P(\\calD).$$\n",
    "\n",
    "We can ignore the evidence term $P(\\calD)$, because it is independent of $\\theta$ the optimization variable. The original problem reduces to maximizing the posterior, hence maximum a posteriori:\n",
    "\n",
    "$$ \\theta^* = \\arg~\\max_\\theta P(\\theta|\\calD)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91e38f3-473e-4bbb-994e-b2a5d22ef34b",
   "metadata": {},
   "source": [
    "#### Q25: Define L-p norm for $p = \\{1, 2, \\dots \\}$\n",
    "\n",
    "$$ \\|\\bfx\\|_p = \\left(|x_1|^p + |x_2|^p + \\dots + |x_n|^p \\right)^{\\frac{1}{p}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2265f04c-02bb-4d38-8ec2-9041f78987fe",
   "metadata": {},
   "source": [
    "#### Q26: Find the minimum point for the following regularized least square problem and \n",
    "$\\newcommand{\\bfw}{\\mathbf{w}}$\n",
    "$\\newcommand{\\bfX}{\\mathbf{X}}$\n",
    "$\\newcommand{\\bfy}{\\mathbf{y}}$\n",
    "$$\\bfw^* = \\arg~\\min_\\bfw \\|\\bfy - \\bfX \\bfw\\|^2 + \\lambda \\|\\bfw\\|^2, $$\n",
    "where $\\bfw \\in \\bbR^n$, $\\bfy \\in \\bbR^m$, $\\bfX \\in \\bbR^{m \\times n}$ and $\\lambda \\in \\bbR^+$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190a413b-8d65-43a4-beb2-a9ad2ddfe8bf",
   "metadata": {},
   "source": [
    "#### A26:\n",
    "\n",
    "Let $f(\\bfw) = \\|\\bfy - \\bfX \\bfw\\|^2 + \\lambda \\|\\bfw\\|^2$\n",
    "\n",
    "Write $f(\\bfw)$ in terms of inner product,\n",
    "$$f(\\bfw) = (\\bfy - \\bfX \\bfw)^\\top(\\bfy - \\bfX \\bfw) + \\lambda \\bfw^\\top \\bfw$$\n",
    "\n",
    "Expand and collect the terms,\n",
    "$$f(\\bfw) = \\bfw^\\top (\\bfX^\\top \\bfX + \\lambda I_n) \\bfw - 2\\bfy^\\top \\bfX \\bfw + \\bfy^\\top \\bfy $$\n",
    "\n",
    "\n",
    "\n",
    "Taking the derivative of $f(\\bfw)$ we get,\n",
    "$$\\frac{\\partial}{\\partial \\bfw} f(\\bfw) = 2 \\bfw^\\top(\\bfX^\\top \\bfX + \\lambda I_n)  - 2\\bfy^\\top \\bfX.$$\n",
    "\n",
    "At the maximum point $\\bfw^*$ the derivative of $f(\\bfw)$ is zero,\n",
    "\n",
    "$$\\left.\\frac{\\partial}{\\partial \\bfw} f(\\bfw)\\right|_{\\bfw^*} = \\mathbf{0}^\\top_n,$$\n",
    "\n",
    "Equating the derivative to zero at $\\bfw^*$, we can solve for $\\bfw^*$,\n",
    "$$2 \\bfw^{*\\top}(\\bfX^\\top \\bfX + \\lambda I_n)  - 2\\bfy^\\top \\bfX = \\mathbf{0}^\\top_n.$$\n",
    "\n",
    "Rearranging we get,\n",
    "$$\\bfw^* = (\\bfX^\\top \\bfX + \\lambda I_n)^{-1} \\bfX^\\top \\bfy$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
